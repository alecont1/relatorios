---
phase: 01-setup-infrastructure
plan: 04
type: execute
wave: 2
depends_on: ["01-02"]
files_modified:
  - backend/app/services/__init__.py
  - backend/app/services/storage.py
  - backend/tests/__init__.py
  - backend/tests/test_storage.py
autonomous: true

must_haves:
  truths:
    - "Storage service can generate presigned upload URLs"
    - "Storage service can generate presigned download URLs"
    - "Storage service can list objects with prefix filtering"
    - "Storage service can delete objects"
    - "R2 storage is accessible with configured credentials from environment"
  artifacts:
    - path: "backend/app/services/storage.py"
      provides: "Cloudflare R2 storage client wrapper"
      exports: ["StorageService", "get_storage_service"]
    - path: "backend/tests/test_storage.py"
      provides: "Unit tests for storage service"
      contains: "test_generate_upload_url"
  key_links:
    - from: "backend/app/services/storage.py"
      to: "backend/app/core/config.py"
      via: "R2 credentials from settings"
      pattern: "settings\\.r2_"
    - from: "backend/app/services/storage.py"
      to: "boto3"
      via: "S3-compatible client with custom endpoint"
      pattern: "endpoint_url.*r2_endpoint"
---

<objective>
Create the Cloudflare R2 storage service using boto3 with S3-compatible API for photo storage operations.

Purpose: Establish the object storage layer that the photo upload and retrieval features will use.
Output: A StorageService class that wraps boto3 S3 operations with R2-specific configuration.
</objective>

<execution_context>
@C:\Users\xande\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\xande\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/01-setup-infrastructure/01-02-SUMMARY.md

Research findings (from planning context):
- Cloudflare R2: boto3 with endpoint_url pointing to account R2 URL, region_name='auto'
- Zero egress fees for photo downloads
- S3-compatible client library (boto3)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create R2 storage service</name>
  <files>
    backend/app/services/__init__.py
    backend/app/services/storage.py
  </files>
  <action>
    1. Create backend/app/services/__init__.py (empty)

    2. Create backend/app/services/storage.py:

    ```python
    import boto3
    from botocore.config import Config as BotoConfig
    from app.core.config import settings
    import uuid
    from typing import Optional

    class StorageService:
        """Cloudflare R2 storage service using S3-compatible API."""

        def __init__(self):
            self._client = boto3.client(
                "s3",
                endpoint_url=settings.r2_endpoint_url,
                aws_access_key_id=settings.r2_access_key_id,
                aws_secret_access_key=settings.r2_secret_access_key,
                region_name="auto",
                config=BotoConfig(
                    signature_version="s3v4",
                    s3={"addressing_style": "path"},
                ),
            )
            self._bucket = settings.r2_bucket_name

        def generate_upload_url(
            self,
            tenant_id: str,
            filename: str,
            content_type: str = "image/jpeg",
            expires_in: int = 3600,
        ) -> tuple[str, str]:
            """Generate presigned URL for upload. Returns (url, object_key)."""
            ext = filename.rsplit(".", 1)[-1] if "." in filename else "jpg"
            object_key = f"{tenant_id}/photos/{uuid.uuid4()}.{ext}"

            url = self._client.generate_presigned_url(
                "put_object",
                Params={
                    "Bucket": self._bucket,
                    "Key": object_key,
                    "ContentType": content_type,
                },
                ExpiresIn=expires_in,
            )
            return url, object_key

        def generate_download_url(
            self,
            object_key: str,
            expires_in: int = 3600,
        ) -> str:
            """Generate presigned URL for download."""
            return self._client.generate_presigned_url(
                "get_object",
                Params={
                    "Bucket": self._bucket,
                    "Key": object_key,
                },
                ExpiresIn=expires_in,
            )

        def delete_object(self, object_key: str) -> None:
            """Delete an object from storage."""
            self._client.delete_object(
                Bucket=self._bucket,
                Key=object_key,
            )

        def list_objects(
            self,
            prefix: str,
            max_keys: int = 100,
        ) -> list[dict]:
            """List objects with given prefix. Returns list of {key, size, last_modified}."""
            response = self._client.list_objects_v2(
                Bucket=self._bucket,
                Prefix=prefix,
                MaxKeys=max_keys,
            )
            contents = response.get("Contents", [])
            return [
                {
                    "key": obj["Key"],
                    "size": obj["Size"],
                    "last_modified": obj["LastModified"].isoformat(),
                }
                for obj in contents
            ]

    # Singleton instance (lazy)
    _storage_service: Optional[StorageService] = None

    def get_storage_service() -> StorageService:
        """Get or create storage service instance."""
        global _storage_service
        if _storage_service is None:
            _storage_service = StorageService()
        return _storage_service
    ```
  </action>
  <verify>
    cd backend && python -c "from app.services.storage import StorageService, get_storage_service; print('Storage service imports OK')"
  </verify>
  <done>StorageService class handles upload/download URL generation, object deletion, and listing via boto3 S3-compatible API</done>
</task>

<task type="auto">
  <name>Task 2: Create storage service unit tests</name>
  <files>
    backend/tests/__init__.py
    backend/tests/test_storage.py
  </files>
  <action>
    1. Create backend/tests/__init__.py (empty)

    2. Create backend/tests/test_storage.py:
       - Use unittest.mock to mock boto3 client
       - Test cases:
         a. test_generate_upload_url: Verify presigned URL generation called with correct params, returns (url, key) tuple, key follows tenant_id/photos/uuid.ext pattern
         b. test_generate_download_url: Verify get_object presigned URL generation
         c. test_delete_object: Verify delete_object called with correct bucket/key
         d. test_list_objects: Verify list_objects_v2 called with prefix, response parsed correctly
         e. test_upload_url_uses_content_type: Verify ContentType param is passed through
         f. test_object_key_format: Verify key format is {tenant_id}/photos/{uuid}.{ext}

       Use @patch("app.services.storage.boto3.client") to mock the boto3 client.
       Mock settings with appropriate test values for R2 config.

       Example test structure:
       ```python
       import pytest
       from unittest.mock import patch, MagicMock
       from app.services.storage import StorageService

       @patch("app.services.storage.boto3.client")
       @patch("app.services.storage.settings")
       def test_generate_upload_url(mock_settings, mock_boto_client):
           mock_settings.r2_endpoint_url = "https://test.r2.cloudflarestorage.com"
           mock_settings.r2_access_key_id = "test-key"
           mock_settings.r2_secret_access_key = "test-secret"
           mock_settings.r2_bucket_name = "test-bucket"

           mock_client = MagicMock()
           mock_boto_client.return_value = mock_client
           mock_client.generate_presigned_url.return_value = "https://presigned-url"

           service = StorageService()
           url, key = service.generate_upload_url("tenant-123", "photo.jpg")

           assert url == "https://presigned-url"
           assert "tenant-123/photos/" in key
           assert key.endswith(".jpg")
       ```
  </action>
  <verify>
    cd backend && python -m pytest tests/test_storage.py -v
    Expected: All tests pass
  </verify>
  <done>Storage service has comprehensive unit tests covering all operations with mocked boto3 client</done>
</task>

</tasks>

<verification>
1. `from app.services.storage import StorageService` imports without errors
2. `python -m pytest tests/test_storage.py -v` passes all tests
3. StorageService uses settings.r2_* for configuration
4. Object keys follow {tenant_id}/photos/{uuid}.{ext} pattern
5. Presigned URLs use correct S3 operations (put_object, get_object)
</verification>

<success_criteria>
- StorageService wraps boto3 with R2-specific config (endpoint_url, region auto)
- Upload URL generation creates tenant-scoped object keys
- Download URL generation works with any object key
- Delete and list operations are functional
- All unit tests pass with mocked boto3
</success_criteria>

<output>
After completion, create `.planning/phases/01-setup-infrastructure/01-04-SUMMARY.md`
</output>
